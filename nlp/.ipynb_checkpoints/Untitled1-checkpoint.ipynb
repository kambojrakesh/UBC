{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "36d2f9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "def find_best_k(word2vec_model, analogies, k_start, k_end):\n",
    "    best_k = 0\n",
    "    max_correct = 0\n",
    "    \n",
    "    for k in range(k_start, k_end+1):\n",
    "        #print(k, \"-------------\")\n",
    "        svd = TruncatedSVD(n_components=k)\n",
    "        reduced_vectors = svd.fit_transform(word2vec_model.vectors)\n",
    "        \n",
    "        correct = 0\n",
    "        for analogy in analogies:\n",
    "            #print(analogy, \"-------------\")\n",
    "            word1, word2, word3, expected = analogy\n",
    "            word1_index = word2vec_model.key_to_index.get(word1, None)\n",
    "            word2_index = word2vec_model.key_to_index.get(word2, None)\n",
    "            word3_index = word2vec_model.key_to_index.get(word3, None)\n",
    "            \n",
    "            if word1_index is None or word2_index is None or word3_index is None:\n",
    "                continue\n",
    "                \n",
    "            word1_vec = reduced_vectors[word1_index]\n",
    "            word2_vec = reduced_vectors[word2_index]\n",
    "            word3_vec = reduced_vectors[word3_index]\n",
    "            \n",
    "            word4_vec = word3_vec - word2_vec + word1_vec\n",
    "            closest_index = cosine_similarity(word4_vec.reshape(1, -1), reduced_vectors).argmax()\n",
    "            closest_word = word2vec_model.index_to_key[closest_index]\n",
    "            \n",
    "            if closest_word == expected:\n",
    "                correct += 1\n",
    "        \n",
    "    \n",
    "        if correct > max_correct:\n",
    "            max_correct = correct\n",
    "            best_k = k\n",
    "            \n",
    "    return best_k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0631404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from nltk.data import find\n",
    "word2vec_sample = str(find('models/word2vec_sample/pruned.word2vec.txt'))\n",
    "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format(word2vec_sample, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319e86bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "analogies = [('ATHENS', 'GREECE', 'BANGKOK', 'China'),  ('ATHENS', 'GREECE', 'BERLIN', 'GERMANY'),   ('ATHENS', 'GREECE', 'BERN', 'SWITZERLAND')]\n",
    "best_k = find_best_k(word2vec_model, analogies, 10, 50)\n",
    "print(best_k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7fe48f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
